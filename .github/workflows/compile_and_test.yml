# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions
#         python -m pytest --ignore=rational/mxnet/tests --ignore=rational/keras/tests/ -k rational/torch/tests/
name: CI-CD

on:
  push:
    branches: [ ci-cd, master ]

jobs:
  build-and-test-cuda101:
    name: Tests Cuda 10.1, Python =
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.6', '3.7', '3.8']
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Current dir
      run: pwd
    - run: nvidia-smi
    - name: Create new python env (on self-hosted runners we have to handle isolation ourselves)
      run: |
        python -m venv .env
        source .env/bin/activate
    - name: Install dependencies
      run: |
        source .env/bin/activate
        pip install --upgrade pip
        pip install airspeed matplotlib pytest scipy wheel
        # pip install torch==1.7.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html
        # We need to export correct pointers for CUDA_HOME and nvcc that corresond to the correct CUDA version.
        echo "CUDA_HOME=/usr/local/cuda-10.1/" >> $GITHUB_ENV
        echo "PATH=/usr/local/cuda-10.1/bin:$PATH" >> $GITHUB_ENV  # instead of alias nvcc="/usr/local/cuda-10.1/bin/nvcc"
        echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.1/targets/x86_64-linux/lib" >> $GITHUB_ENV
        echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.1/extras/CUPTI/lib64" >> $GITHUB_ENV
    - name: Check Python and CUDA versions
      run: |
        source .env/bin/activate
        python --version
        python -c "import sys; print('Python version:', sys.version)"
        python -c "import torch; print('Cuda available:', torch.cuda.is_available())"
        python -c "import torch; print('CUDA version used by PyTorch:', torch.version.cuda)"
        nvcc --version
        echo CUDA_HOME: $CUDA_HOME
    - name: Install package
      run: |
        source .env/bin/activate
        echo 'Installed!'
    - name: Test
      run: |
        source .env/bin/activate
        echo 'All Tests passed!'
    - name: Upload to Pypi
      run: |
        echo Uploaded!
  build-and-test-cuda102:
    name: Tests Cuda 10.2, Python =
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.6', '3.7', '3.8']
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - name: Current dir
        run: pwd
      - run: nvidia-smi
      - name: Create new python env (on self-hosted runners we have to handle isolation ourselves)
        run: |
          python -m venv .env
          source .env/bin/activate
      - name: Install dependencies
        run: |
          source .env/bin/activate
          pip install --upgrade pip
          # pip install airspeed matplotlib pytest scipy torch==1.7.1 wheel
          # We need to export correct pointers for CUDA_HOME and nvcc that corresond to the correct CUDA version.
          echo "CUDA_HOME=/usr/local/cuda-10.2/" >> $GITHUB_ENV
          echo "PATH=/usr/local/cuda-10.2/bin:$PATH" >> $GITHUB_ENV  # instead of alias nvcc="/usr/local/cuda-10.2/bin/nvcc"
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.2/targets/x86_64-linux/lib" >> $GITHUB_ENV
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.2/extras/CUPTI/lib64" >> $GITHUB_ENV
      - name: Check Python and CUDA versions
        run: |
          source .env/bin/activate
          python --version
          python -c "import sys; print('Python version:', sys.version)"
          python -c "import torch; print('Cuda available:', torch.cuda.is_available())"
          python -c "import torch; print('CUDA version used by PyTorch:', torch.version.cuda)"
          nvcc --version
          echo CUDA_HOME: $CUDA_HOME
      - name: Install package
        run: |
          source .env/bin/activate
          echo 'Installed!'
      - name: Test
        run: |
          source .env/bin/activate
          echo 'All Tests passed!'
      - name: Upload to Pypi
        run: |
          echo Uploaded!

  linting:
    name: Lint with PyLint
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.6','3.7', '3.8']
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - name: Create new python env (on self-hosted runners we have to handle isolation ourselves)
        run: |
          python -m venv .env
          source .env/bin/activate
      - name: Set CUDA related environment variables
        run: |
          # We need to export correct pointers for CUDA_HOME and nvcc that corresond to the correct CUDA version.
          source .env/bin/activate
          echo "CUDA_HOME=/usr/local/cuda-10.2/" >> $GITHUB_ENV
          echo "PATH=/usr/local/cuda-10.2/bin:$PATH" >> $GITHUB_ENV  # instead of alias nvcc="/usr/local/cuda-10.2/bin/nvcc"
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.2/targets/x86_64-linux/lib" >> $GITHUB_ENV
          echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.2/extras/CUPTI/lib64" >> $GITHUB_ENV
      - name: Install dependencies
        run: |
          source .env/bin/activate
          pip install --upgrade pip
          pip install -r .github/workflows/dev-requirements.txt
          pip install mxnet-cu102 torch==1.7.1
          pip install tensorflow-gpu # $(python .github/workflows/get_tensorflow_wheel.py | tail -1)
      - name: Lint with PyLint
        run: |
          pylint .