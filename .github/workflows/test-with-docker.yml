# action.yml
name: Python test
on:
  push:
    branches: [ ci-cd ]
jobs:
  gpu_checks:
    name: Tests (Cuda, Python) =
    runs-on: self-hosted
    strategy:
      matrix:
        cuda-version: ['10.2']
        python-version: ['3.8']
    steps:
    - uses: actions/checkout@v2
      with:
        cuda-version: ${{ matrix.cuda-version }}
        python-version: ${{ matrix.python-version }}
    - name: Run GPU tests CUDA=${{ matrix.cuda-version }} & Python${{ matrix.python-version }}
      run: |
        docker run -i --gpus device=all --rm --name cuda102py38_container cuda102py38
        python -c "import torch; print('Cuda available:', torch.cuda.is_available())"
        python -c "import sys; print('Python version:', sys.version)"
        python -c "import torch; print('Number of GPUs available:', torch.cuda.device_count(), 'CUDA version:', torch.version.cuda)"
        pip install --upgrade pip
        pip install -r requirements.txt

        nvcc --version
        echo CUDA_HOME: $$CUDA_HOME
        echo PATH: $$PATH

        nvidia-smi
        python setup.py develop --user
        python -m pytest


# run: |
#        echo "CUDA_HOME=/usr/local/cuda-10.2/" >> $GITHUB_ENV
#        echo "PATH=/usr/local/cuda-10.2/bin:$PATH" >> $GITHUB_ENV